{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4ed57f3",
   "metadata": {},
   "source": [
    "# Creating a misinformation detection model using TF-IDF vectorization \n",
    "1. Compile training data from Kaggle dataset of fake and real news articles. Use the article urls to fetch the article text\n",
    "2. Clean and tokenize the data\n",
    "3. Create TF-IDF vectors to use in the model\n",
    "4. Evaluate the performance of different classification models using the TF-IDF model\n",
    "5. Implement the optimal model on the YouTube captions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "684a20a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import requests\n",
    "from newspaper import Article\n",
    "\n",
    "import re \n",
    "import nltk.corpus\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16492a18",
   "metadata": {},
   "source": [
    "### Fetch both real and fake news articles to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13e5ee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df = pd.read_csv(\"../src/model/politifact_fake.csv\")\n",
    "real_df = pd.read_csv(\"../src/model/politifact_real.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e05f3c",
   "metadata": {},
   "source": [
    "### Gather article texts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e7d9c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_link_article(url):\n",
    "    result_json = None\n",
    "\n",
    "    try:\n",
    "        if 'http' not in url:\n",
    "            if url[0] == '/':\n",
    "                url = url[1:]\n",
    "            try:\n",
    "                article = Article('http://' + url)\n",
    "                article.download()\n",
    "                time.sleep(2)\n",
    "                article.parse()\n",
    "                flag = True\n",
    "            except:\n",
    "                flag = False\n",
    "                pass\n",
    "            if flag == False:\n",
    "                try:\n",
    "                    article = Article('https://' + url)\n",
    "                    article.download()\n",
    "                    time.sleep(2)\n",
    "                    article.parse()\n",
    "                    flag = True\n",
    "                except:\n",
    "                    flag = False\n",
    "                    pass\n",
    "            if flag == False:\n",
    "                return None\n",
    "        else:\n",
    "            try:\n",
    "                article = Article(url)\n",
    "                article.download()\n",
    "                time.sleep(2)\n",
    "                article.parse()\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "        if not article.is_parsed:\n",
    "            return None\n",
    "\n",
    "        visible_text = article.text\n",
    "        top_image = article.top_image\n",
    "        images = article.images\n",
    "        keywords = article.keywords\n",
    "        authors = article.authors\n",
    "        canonical_link = article.canonical_link\n",
    "        title = article.title\n",
    "        meta_data = article.meta_data\n",
    "        movies = article.movies\n",
    "        publish_date = article.publish_date\n",
    "        source = article.source_url\n",
    "        summary = article.summary\n",
    "\n",
    "        result_json = {'url': url, 'text': visible_text, 'images': list(images), 'top_img': top_image,\n",
    "                       'keywords': keywords,\n",
    "                       'authors': authors, 'canonical_link': canonical_link, 'title': title, 'meta_data': meta_data,\n",
    "                       'movies': movies, 'publish_date': get_epoch_time(publish_date), 'source': source,\n",
    "                       'summary': summary}\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    return visible_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c0b911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epoch_time(time_obj):\n",
    "    if time_obj:\n",
    "        return time_obj.timestamp()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b27ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_web_archieve_results(search_url):\n",
    "    try:\n",
    "        archieve_url = \"http://web.archive.org/cdx/search/cdx?url={}&output=json\".format(search_url)\n",
    "\n",
    "        response = requests.get(archieve_url)\n",
    "        response_json = json.loads(response.content)\n",
    "\n",
    "        response_json = response_json[1:]\n",
    "\n",
    "        return response_json\n",
    "\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79188aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_website_url_from_arhieve(url):\n",
    "    \"\"\" Get the url from http://web.archive.org/ for the passed url if exists.\"\"\"\n",
    "    archieve_results = get_web_archieve_results(url)\n",
    "    if archieve_results:\n",
    "        modified_url = \"https://web.archive.org/web/{}/{}\".format(archieve_results[0][1], archieve_results[0][2])\n",
    "        return modified_url\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d014135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_news_article(url):\n",
    "    news_article = crawl_link_article(url)\n",
    "\n",
    "    # If the news article could not be fetched from original website, fetch from archieve if it exists.\n",
    "    if news_article is None:\n",
    "        archieve_url = get_website_url_from_arhieve(url)\n",
    "        if archieve_url is not None:\n",
    "            news_article = crawl_link_article(archieve_url)\n",
    "\n",
    "    return news_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25e6fc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df[\"article_text\"] = fake_df[\"news_url\"].apply(crawl_news_article)\n",
    "fake_df[\"label\"] = \"fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b146fe43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>news_url</th>\n",
       "      <th>title</th>\n",
       "      <th>tweet_ids</th>\n",
       "      <th>article_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>politifact15014</td>\n",
       "      <td>speedtalk.com/forum/viewtopic.php?t=51650</td>\n",
       "      <td>BREAKING: First NFL Team Declares Bankruptcy O...</td>\n",
       "      <td>937349434668498944\\t937379378006282240\\t937380...</td>\n",
       "      <td>None</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politifact15156</td>\n",
       "      <td>politics2020.info/index.php/2018/03/13/court-o...</td>\n",
       "      <td>Court Orders Obama To Pay $400 Million In Rest...</td>\n",
       "      <td>972666281441878016\\t972678396575559680\\t972827...</td>\n",
       "      <td>The West Texas Federal Appeals Court, operatin...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politifact14745</td>\n",
       "      <td>www.nscdscamps.org/blog/category/parenting/467...</td>\n",
       "      <td>UPDATE: Second Roy Moore Accuser Works For Mic...</td>\n",
       "      <td>929405740732870656\\t929439450400264192\\t929439...</td>\n",
       "      <td>Read original article here\\n\\nLiberals sure ar...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>politifact14355</td>\n",
       "      <td>https://howafrica.com/oscar-pistorius-attempts...</td>\n",
       "      <td>Oscar Pistorius Attempts To Commit Suicide</td>\n",
       "      <td>886941526458347521\\t887011300278194176\\t887023...</td>\n",
       "      <td>The former Paralympic athlete reportedly tried...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>politifact15371</td>\n",
       "      <td>http://washingtonsources.org/trump-votes-for-d...</td>\n",
       "      <td>Trump Votes For Death Penalty For Being Gay</td>\n",
       "      <td>915205698212040704\\t915242076681506816\\t915249...</td>\n",
       "      <td>It's possible that Travis Barker's new profile...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                           news_url  \\\n",
       "0  politifact15014          speedtalk.com/forum/viewtopic.php?t=51650   \n",
       "1  politifact15156  politics2020.info/index.php/2018/03/13/court-o...   \n",
       "2  politifact14745  www.nscdscamps.org/blog/category/parenting/467...   \n",
       "3  politifact14355  https://howafrica.com/oscar-pistorius-attempts...   \n",
       "4  politifact15371  http://washingtonsources.org/trump-votes-for-d...   \n",
       "\n",
       "                                               title  \\\n",
       "0  BREAKING: First NFL Team Declares Bankruptcy O...   \n",
       "1  Court Orders Obama To Pay $400 Million In Rest...   \n",
       "2  UPDATE: Second Roy Moore Accuser Works For Mic...   \n",
       "3         Oscar Pistorius Attempts To Commit Suicide   \n",
       "4        Trump Votes For Death Penalty For Being Gay   \n",
       "\n",
       "                                           tweet_ids  \\\n",
       "0  937349434668498944\\t937379378006282240\\t937380...   \n",
       "1  972666281441878016\\t972678396575559680\\t972827...   \n",
       "2  929405740732870656\\t929439450400264192\\t929439...   \n",
       "3  886941526458347521\\t887011300278194176\\t887023...   \n",
       "4  915205698212040704\\t915242076681506816\\t915249...   \n",
       "\n",
       "                                        article_text label  \n",
       "0                                               None  fake  \n",
       "1  The West Texas Federal Appeals Court, operatin...  fake  \n",
       "2  Read original article here\\n\\nLiberals sure ar...  fake  \n",
       "3  The former Paralympic athlete reportedly tried...  fake  \n",
       "4  It's possible that Travis Barker's new profile...  fake  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bd33ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df[\"article_text\"] = real_df[\"news_url\"].apply(crawl_news_article)\n",
    "real_df[\"label\"] = \"real\"\n",
    "\n",
    "news_df = pd.concat([fake_df, real_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90d490da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(video_caption):\n",
    "    if video_caption is not None:\n",
    "        # normalize case\n",
    "        video_caption = video_caption.lower()\n",
    "        # remove punctuation\n",
    "        video_caption = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", video_caption)\n",
    "        # remove stopwords\n",
    "        stop = stopwords.words('english')\n",
    "        video_caption = \" \".join([word for word in video_caption.split() if word not in (stop)])\n",
    "        # lemmenization\n",
    "        wn = nltk.WordNetLemmatizer()\n",
    "        video_caption = \" \".join([wn.lemmatize(word) for word in video_caption.split()])\n",
    "    return video_caption\n",
    "\n",
    "def create_model_df(row):\n",
    "    row = row[[\"article_text\", \"title\", \"label\"]]\n",
    "    row[\"article_text\"] = text_cleaning(row[\"article_text\"])\n",
    "    row[\"title\"] = text_cleaning(row[\"title\"])\n",
    "    row[\"label\"] = int(row[\"label\"] == \"real\")\n",
    "    return row\n",
    "\n",
    "model_data = news_df.apply(create_model_df, axis=1).dropna().reset_index(drop=True)\n",
    "Data = model_data[\"article_text\"]\n",
    "Target = model_data[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9126e2",
   "metadata": {},
   "source": [
    "### Create TF-IDF vectors for every text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3153247",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer.fit_transform(Data)\n",
    "freq_term_matrix = count_vectorizer.transform(Data)\n",
    "tfidf = TfidfTransformer(norm = \"l2\")\n",
    "tfidf.fit(freq_term_matrix)\n",
    "tf_idf_matrix = tfidf.fit_transform(freq_term_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99b440e",
   "metadata": {},
   "source": [
    "### Test/Train split of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07e8ba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tf_idf_matrix, Target, test_size=0.2, random_state=0, stratify=Target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c302222",
   "metadata": {},
   "source": [
    "### Evaluate Logistic Regression, Naive Bayes, Descision Tree, and Passive Agressive Classifiers to find the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41abbb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7048780487804879"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "Accuracy = logreg.score(X_test, y_test)\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09820a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6341463414634146"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB = MultinomialNB()\n",
    "NB.fit(X_train, y_train)\n",
    "Accuracy = NB.score(X_test, y_test)\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a612c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7853658536585366"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "Accuracy = clf.score(X_test, y_test)\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1809c148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7902439024390244"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pac=PassiveAggressiveClassifier(max_iter=50)\n",
    "pac.fit(X_train,y_train)\n",
    "y_pred=pac.predict(X_test)\n",
    "Accuracy=accuracy_score(y_test,y_pred)\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2997fdd4",
   "metadata": {},
   "source": [
    "### Use the best model (Passive Agressive Classifier) to classify YouTube captions as misinformation or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a814fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_captions = pd.read_csv(\"../data/caption_data.csv\")\n",
    "vid_data  = video_captions.dropna()['text'].apply(text_cleaning)\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer.fit_transform(vid_data)\n",
    "freq_term_matrix = count_vectorizer.transform(vid_data)\n",
    "tfidf = TfidfTransformer(norm = \"l2\")\n",
    "tfidf.fit(freq_term_matrix)\n",
    "vid_tf_idf_matrix = tfidf.fit_transform(freq_term_matrix)\n",
    "\n",
    "vid_pred = pac.predict(vid_tf_idf_matrix)\n",
    "misinformation_pct = 1 - (sum(vid_pred) / len(vid_pred))\n",
    "\n",
    "print(f'The percentage of YouTube captions that were classified as misinformation is {misinformation_pct}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
